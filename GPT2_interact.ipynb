{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_interact.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo9FPJoxhpgU",
        "outputId": "8bb0fa89-4ce1-4558-99e6-8db907aca702"
      },
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = '774M'\n",
        "\n",
        "subdir = os.path.join('models', model)\n",
        "if not os.path.exists(subdir):\n",
        "    os.makedirs(subdir)\n",
        "subdir = subdir.replace('\\\\','/') # needed for Windows\n",
        "\n",
        "for filename in ['checkpoint','encoder.json','hparams.json','model.ckpt.data-00000-of-00001', 'model.ckpt.index', 'model.ckpt.meta', 'vocab.bpe']:\n",
        "\n",
        "    r = requests.get(\"https://openaipublic.blob.core.windows.net/gpt-2/\" + subdir + \"/\" + filename, stream=True)\n",
        "\n",
        "    with open(os.path.join(subdir, filename), 'wb') as f:\n",
        "        file_size = int(r.headers[\"content-length\"])\n",
        "        chunk_size = 1000\n",
        "        with tqdm(ncols=100, desc=\"Fetching \" + filename, total=file_size, unit_scale=True) as pbar:\n",
        "            # 1k for chunk_size, since Ethernet packet size is around 1500 bytes\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                f.write(chunk)\n",
        "                pbar.update(chunk_size)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (54.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 405kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 2.06Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 207kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:39, 31.0Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 3.26Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 2.42Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.27Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLGTmgI7huVt"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import model, sample, encoder\n",
        "\n",
        "def interact_model(\n",
        "    model_name='774M',\n",
        "    seed=None,\n",
        "    nsamples=10,\n",
        "    batch_size=1,\n",
        "    length=None,\n",
        "    temperature=1,\n",
        "    top_k=40,\n",
        "    top_p=1,\n",
        "    models_dir='models',\n",
        "):\n",
        "    \"\"\"\n",
        "    Interactively run the model\n",
        "    :model_name=124M : String, which model to use\n",
        "    :seed=None : Integer seed for random number generators, fix seed to reproduce\n",
        "     results\n",
        "    :nsamples=1 : Number of samples to return total\n",
        "    :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n",
        "    :length=None : Number of tokens in generated text, if None (default), is\n",
        "     determined by model hyperparameters\n",
        "    :temperature=1 : Float value controlling randomness in boltzmann\n",
        "     distribution. Lower temperature results in less random completions. As the\n",
        "     temperature approaches zero, the model will become deterministic and\n",
        "     repetitive. Higher temperature results in more random completions.\n",
        "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
        "     considered for each step (token), resulting in deterministic completions,\n",
        "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
        "     special setting meaning no restrictions. 40 generally is a good value.\n",
        "     :models_dir : path to parent folder containing model subfolders\n",
        "     (i.e. contains the <model_name> folder)\n",
        "    \"\"\"\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k, top_p=top_p\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        while True:\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "            while not raw_text:\n",
        "                print('Prompt should not be empty!')\n",
        "                raw_text = input(\"Model prompt >>> \")\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "            generated = 0\n",
        "            for _ in range(nsamples // batch_size):\n",
        "                out = sess.run(output, feed_dict={\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "                })[:, len(context_tokens):]\n",
        "                for i in range(batch_size):\n",
        "                    generated += 1\n",
        "                    text = enc.decode(out[i])\n",
        "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "                    print(text)\n",
        "            print(\"=\" * 80)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfS-T-a-hygX",
        "outputId": "441da223-5a33-4f16-e2eb-e0a82c8c4e65"
      },
      "source": [
        "interact_model(model_name='774M')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "INFO:tensorflow:Restoring parameters from models/774M/model.ckpt\n",
            "Model prompt >>> what is the value of pi\n",
            "======================================== SAMPLE 1 ========================================\n",
            " and why is it so important to them? We will investigate this issue of pi and other mathematical quantities in the next lesson. In the meantime, we will discuss the relationship between the different physical constants and their importance.\n",
            "\n",
            "Next Time<|endoftext|>TOMS RIVER â€” After a decade, the Tomson River is moving a step closer to being officially named an urban park\n",
            "\n",
            "The New Jersey Wildlife and Recreation Planning Council voted Monday night that the river was officially named the New Jersey Urban Park, in an effort to get it on the short list for designation as a National Historic District.\n",
            "\n",
            "The city plans to complete the application process in coming weeks, according to the city attorney's office.\n",
            "\n",
            "The Urban Park designation will allow New Jersey Parks and Wildlife to begin construction on the first phase of Tomson River Park, which would encompass about 13 acres, the city said. While the city has not yet said where the park will be located, the area could serve as the first location for a public park within the New Jersey Urban Park Program as part of its $5 million plan, which will see public recreation sites come online in various locations across Greater New Jersey.\n",
            "\n",
            "Read more about our city's efforts to help the Tomson River and surrounding areas become a National Historic District.\n",
            "\n",
            "Follow @starledger\n",
            "\n",
            "\n",
            "Have a tip we should know? tips@mediaite.com<|endoftext|>A group of former college football players are demanding that the University of Michigan pay them $10 million in damages for their injuries suffered during their \"Fight for 15\" protests at the school.\n",
            "\n",
            "The players filed a $10 million lawsuit on Monday against the University, the Michigan Athletic Association, its directors and coaches, the schools of the University of Michigan and Michigan State and its athletic director, James Gill, and the Michigan Senate.\n",
            "\n",
            "\"To my knowledge, most of these plaintiffs have received approximately $900,000 in settlements in settlements related to their injuries, although most of those settlements were based on claims of a lower grade,\" the players said in their lawsuit, which was filed in U.S. District Court in Ann Arbor.\n",
            "\n",
            "\"However, some plaintiffs are seeking to recoup the costs stemming from their injuries and injuries incurred as part of their collective actions on or near the January 1, 2012 date,\" according to the lawsuit.\n",
            "\n",
            "The players claim negligence by the university and the university's department of athletic department administrators, as well as failure to ensure the \"Safe Zone\" around the stadium was properly protected by the athletic department.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}